{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "random.seed(12)\n",
    "\n",
    "import numpy as np\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../../utils_paper/')\n",
    "from conllUtils import describe_entities, group_conll\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and dev corpus construction for medpost corpus\n",
    "\n",
    "We build a train and dev set from the [medpost corpus](http://biocreative.sourceforge.net/bio_corpora_links.html) ([download link](ftp://ftp.ncbi.nlm.nih.gov/pub/lsmith/MedTag/medtag.tar.gz)). The MedPost corpus consists of 6 700 sentences, and is annotated with parts of speech, and gerund arguments. It is based on MEDLINE abstracts, the original paper describing the construction of the corpus can be found [here](https://academic.oup.com/bioinformatics/article/20/14/2320/213968)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2corpora = '../data/medtag/medpost/'\n",
    "path2texts = [path2corpora + f for f in os.listdir(path2corpora) if os.path.splitext(f)[1] == '.ioc']\n",
    "path2original_dev = ['../data/medtag/medpost/tag_mb.ioc']\n",
    "path2original_train = [f for f in path2texts if f not in path2original_dev]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion to conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific functions to convert medpost format to conll format with bio tagging-scheme\n",
    "def medpost_format2conll(path2file):\n",
    "    new_line = re.compile('P(\\d\\d*)A(\\d\\d*)')\n",
    "    with open(path2file, 'r') as f:\n",
    "        data = f.read().splitlines()\n",
    "    conll = []\n",
    "    prec_label = ''\n",
    "    for l in data:\n",
    "        if new_line.search(l) is not None:\n",
    "            conll.append('\\n')\n",
    "        else:\n",
    "            for token in l.split(' '):\n",
    "                string, label = token.split('_')\n",
    "                if prec_label == label:\n",
    "                    label = 'I-'+label\n",
    "                else:\n",
    "                    label = 'B-'+label\n",
    "                prec_label = label[2:]\n",
    "                conll.append(string + '\\t' + label + '\\n')\n",
    "    return conll\n",
    "\n",
    "# Wrapper for the whole corpus\n",
    "def medpost2conll(path2texts, save_path = None):\n",
    "    corpora_conll = []\n",
    "    for f in path2texts:\n",
    "        text_conll = medpost_format2conll(f)\n",
    "        corpora_conll += text_conll\n",
    "    if save_path is not None:\n",
    "        with open(save_path,'w') as f:\n",
    "            f.writelines(corpora_conll[1:])\n",
    "    return corpora_conll[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2train = '../data/train.conll' \n",
    "path2dev = '../data/dev.conll'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = medpost2conll(path2original_train, save_path = path2train)\n",
    "dev_data = medpost2conll(path2original_dev, save_path = path2dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio #dev/(#dev + #train) = 28766/189020 = 0.152\n"
     ]
    }
   ],
   "source": [
    "print('ratio #dev/(#dev + #train) = {}/{} = {:.3}'.format(len(dev_data), len(dev_data) + len(train_data), len(dev_data)/(len(dev_data) + len(train_data))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fused classes\n",
    "Fusionned some unexplained classes as well as all punctuation in a unique punctation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the evaluation, we would want to reduce the number of classes\n",
    "path2fused_train = '../data/train.conll'\n",
    "path2fused_dev = '../data/dev.conll'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fundamental\\tB-JJ', 'services\\tB-NNS', 'that\\tB-PNR']\n",
      "['fundamental\\tB-JJ\\n', 'services\\tB-NNS\\n', 'that\\tB-PNR\\n']\n",
      "['of\\tB-II', 'human\\tB-NN', 'renal\\tB-JJ']\n",
      "['of\\tB-II\\n', 'human\\tB-NN\\n', 'renal\\tB-JJ\\n']\n"
     ]
    }
   ],
   "source": [
    "# reducing the number of classes\n",
    "punct = [',', '.', ';', ':', ')', '(', '``', \"''\"]\n",
    "grouping = {'PUNCT': punct, 'CC' : ['CC+', 'CC'], 'II' : ['II+', 'II'], 'RR' : ['RR+', 'RR'], 'JJ' : ['JJ+', 'JJ'], 'CS' : ['CS+', 'CS'], 'NN' : ['NN+', 'NN']}\n",
    "fused_train = group_conll(path2train, path2fused_train, grouping)\n",
    "fused_dev = group_conll(path2dev, path2fused_dev, grouping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicit labels extracted from the medpost paper\n",
    "with open('../data/medpost_pos.json') as f:\n",
    "    pos2label = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus containing 154552 tokens in 5702 sentences with 154552 non-O tags\n",
      "Counter({'NN': 39903, 'II': 19042, 'PUNCT': 18649, 'JJ': 12247, 'NNS': 11272, 'DD': 11076, 'CC': 6171, 'MC': 4476, 'VVN': 4092, 'RR': 3927, 'VVNJ': 2122, 'VBD': 2067, 'VVD': 1698, 'VVB': 1656, 'SYM': 1572, 'TO': 1042, 'VBZ': 1035, 'CST': 1025, 'VVGN': 1013, 'VVZ': 970, 'VVI': 892, 'PN': 877, 'VVG': 869, 'VBB': 839, 'VVGJ': 818, 'PNR': 762, 'VM': 670, 'CS': 652, 'PNG': 424, 'PND': 388, 'VHB': 317, 'JJR': 260, 'CSN': 213, 'VBN': 202, 'NNP': 191, 'VHZ': 189, 'VBI': 171, 'VHD': 156, 'EX': 126, 'GE': 106, 'VDD': 105, 'RRT': 81, 'JJT': 42, 'VDZ': 41, 'VDB': 30, 'DB': 28, 'VHI': 18, 'VBG': 14, 'RRR': 8, 'VHG': 4, 'VDN': 4}) \n",
      "\n",
      "Corpus containing 27767 tokens in 999 sentences with 27767 non-O tags\n",
      "Counter({'NN': 7339, 'II': 3453, 'PUNCT': 3148, 'DD': 2178, 'JJ': 2142, 'NNS': 1948, 'CC': 1029, 'MC': 832, 'VVN': 827, 'RR': 692, 'VBD': 405, 'VVNJ': 364, 'VVB': 309, 'VVD': 294, 'SYM': 249, 'CST': 188, 'VBZ': 179, 'TO': 167, 'VVGJ': 164, 'VVZ': 159, 'VVG': 156, 'PN': 152, 'VVGN': 150, 'PNR': 141, 'VBB': 136, 'VVI': 133, 'CS': 126, 'VM': 116, 'PNG': 83, 'PND': 78, 'NNP': 60, 'VHB': 57, 'JJR': 48, 'CSN': 43, 'VBN': 40, 'VBI': 36, 'VHZ': 33, 'VDD': 22, 'VHD': 14, 'EX': 14, 'GE': 12, 'JJT': 11, 'VDZ': 9, 'DB': 7, 'RRT': 7, 'VDB': 6, 'VBG': 4, 'VHI': 3, 'VHG': 2, 'RRR': 2})\n"
     ]
    }
   ],
   "source": [
    "print(describe_entities(path2train), '\\n')\n",
    "print(describe_entities(path2dev))\n",
    "#pos2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus containing 154552 tokens in 5702 sentences with 154552 non-O tags\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'noun': 39903,\n",
       " 'PUNCT': 18649,\n",
       " 'adjective': 12247,\n",
       " 'coordinating conjunction': 6171,\n",
       " 'base be, am, are': 839,\n",
       " 'plural noun': 11272,\n",
       " 'relative pronoun': 762,\n",
       " 'base form lexical verb': 1656,\n",
       " 'genitive marker ’s': 106,\n",
       " 'infinitive marker to': 1042,\n",
       " 'infinitive lexical verb': 892,\n",
       " 'preposition': 19042,\n",
       " 'genitive pronoun': 424,\n",
       " 'number or numeric': 4476,\n",
       " 'past was, were': 2067,\n",
       " 'past part.': 4092,\n",
       " 'subordinating conjunction': 652,\n",
       " 'adverb': 3927,\n",
       " 'prenominal past part.': 2122,\n",
       " 'present part.': 869,\n",
       " 'complementizer (that)': 1025,\n",
       " '3rd pers. sing. is': 1035,\n",
       " 'determiner': 11076,\n",
       " 'prenominal present part.': 818,\n",
       " 'comparative conjunction (than)': 213,\n",
       " 'base have': 317,\n",
       " 'nominal gerund': 1013,\n",
       " 'past tense': 1698,\n",
       " 'comparative adjective': 260,\n",
       " 'existential there': 126,\n",
       " '3rd pers. sing. has': 189,\n",
       " 'participle been': 202,\n",
       " '3rd pers. sing.': 970,\n",
       " 'symbol': 1572,\n",
       " 'pronoun': 877,\n",
       " 'modal': 670,\n",
       " 'superlative adverb': 81,\n",
       " 'infinitive be': 171,\n",
       " 'proper noun': 191,\n",
       " 'determiner as pronoun': 388,\n",
       " 'predeterminer': 28,\n",
       " 'base do': 30,\n",
       " '3rd pers. sing. does': 41,\n",
       " 'superlative adjective': 42,\n",
       " 'comparative adverb': 8,\n",
       " 'past did': 105,\n",
       " 'participle being': 14,\n",
       " 'infinitive have': 18,\n",
       " 'past had': 156,\n",
       " 'participle having': 4,\n",
       " 'participle done': 4}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More human readable but heavier\n",
    "train_ents = describe_entities(path2train)\n",
    "readable_labels = {}\n",
    "for k, v in train_ents.items():\n",
    "    if k in pos2label.keys():\n",
    "        key = pos2label[k]\n",
    "    else:\n",
    "        key = k\n",
    "    readable_labels[key] = v\n",
    "readable_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_tags= 182319, prop= 1.0\n",
      "nb_tokens= 182319, nb_sent 6701\n"
     ]
    }
   ],
   "source": [
    "tot_tagged = 27767 + 154552\n",
    "nb_tokens = 27767 + 154552\n",
    "nb_sents = 5702 + 999\n",
    "print('nb_tags= {}, prop= {}'.format(tot_tagged, tot_tagged/nb_tokens))\n",
    "print('nb_tokens= {}, nb_sent {}'.format(nb_tokens, nb_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus containing 154552 tokens in 5702 sentences\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "print(len(describe_entities(path2fused_train, iob=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus containing 27767 tokens in 999 sentences\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(describe_entities(path2fused_dev, iob=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
